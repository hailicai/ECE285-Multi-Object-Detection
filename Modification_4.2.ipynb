{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning with Birds Data Set and Replacing All Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from misc_utils.tensor_sampling_utils import sample_tensors\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from eval_utils.average_precision_evaluator import Evaluator\n",
    "\n",
    "import os\n",
    "root_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the trained weights file and make a copy\n",
    "Load the VOC pre-trained weight and make a copy for modification. Again, weights can be found here: https://drive.google.com/file/d/1vtNI6kSnv7fkozl7WxyhGyReB6JvDM41/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = os.getcwd()\n",
    "weights_source_path = os.path.join(root_dir,'VGG_VOC0712Plus_SSD_300x300_iter_240000.h5') \n",
    "\n",
    "weights_destination_path = os.path.join(root_dir,'Birds_training_dest.h5') \n",
    "\n",
    "# Make a copy of the weights file.\n",
    "shutil.copy(weights_source_path, weights_destination_path)\n",
    "\n",
    "weights_source_file = h5py.File(weights_source_path, 'r')\n",
    "weights_destination_file = h5py.File(weights_destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Re-initailize classcification layers\n",
    "There are 20 classes + 1 background in the VOC pre-trained model. We want to change all these 20 classes into 20 species of birds, similar to assignment 3. Therefore, we will re-initalize all the classification layers so they can be re-trained on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_names = ['conv4_3_norm_mbox_conf',\n",
    "                    'fc7_mbox_conf',\n",
    "                    'conv6_2_mbox_conf',\n",
    "                    'conv7_2_mbox_conf',\n",
    "                    'conv8_2_mbox_conf',\n",
    "                    'conv9_2_mbox_conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes_source = 21\n",
    "\n",
    "classes_of_interest = 21 \n",
    "\n",
    "for name in classifier_names:\n",
    "    # Get the trained weights for this layer from the source HDF5 weights file.\n",
    "    kernel = weights_source_file[name][name]['kernel:0'].value\n",
    "    bias = weights_source_file[name][name]['bias:0'].value\n",
    "\n",
    "    # Get the shape of the kernel. We're interested in sub-sampling\n",
    "    # the last dimension, 'o'.\n",
    "    height, width, in_channels, out_channels = kernel.shape\n",
    "    \n",
    "    if isinstance(classes_of_interest, (list, tuple)):\n",
    "        subsampling_indices = []\n",
    "        for i in range(int(out_channels/n_classes_source)):\n",
    "            indices = np.array(classes_of_interest) + i * n_classes_source\n",
    "            subsampling_indices.append(indices)\n",
    "        subsampling_indices = list(np.concatenate(subsampling_indices))\n",
    "    elif isinstance(classes_of_interest, int):\n",
    "        subsampling_indices = int(classes_of_interest * (out_channels/n_classes_source))\n",
    "    else:\n",
    "        raise ValueError(\"`classes_of_interest` must be either an integer or a list/tuple.\")\n",
    "    \n",
    "    #re-initialize weights of classifier layers\n",
    "    new_kernel, new_bias = sample_tensors(weights_list=[kernel, bias],\n",
    "                                          sampling_instructions=[height, width, in_channels, subsampling_indices],\n",
    "                                          axes=[[3]], # The one bias dimension corresponds to the last kernel dimension.\n",
    "                                          init=['gaussian', 'zeros'],\n",
    "                                          mean=0.0,\n",
    "                                          stddev=0.005)\n",
    "    \n",
    "    # Delete the old weights from the destination file.\n",
    "    del weights_destination_file[name][name]['kernel:0']\n",
    "    del weights_destination_file[name][name]['bias:0']\n",
    "    # Create new datasets for the sub-sampled weights.\n",
    "    weights_destination_file[name][name].create_dataset(name='kernel:0', data=new_kernel)\n",
    "    weights_destination_file[name][name].create_dataset(name='bias:0', data=new_bias)\n",
    "\n",
    "# Make sure all data is written to our output file before this sub-routine exits.\n",
    "weights_destination_file.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use the Re-initialized Weight for New Training on Birds Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set the model configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [123, 117, 104] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "swap_channels = [2, 1, 0] # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 20 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_pascal = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "scales_coco = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05] # The anchor box scaling factors used in the original SSD300 for the MS COCO datasets\n",
    "scales = scales_pascal\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 100, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build Model and Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 2: Load the re-initialized weights \n",
    "weights_path = os.path.join(root_dir,'Birds_training_load.h5') \n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model. \n",
    "#Adam optimizer is used here since it yields better result. Arguments inside SGD don't matter since they will be redefined later.\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Set up the data generators for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# after adding birds data:  743\n",
      "# after adding birds data:  372\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "bird_dir = os.path.join(root_dir,'dataset/bird_data')\n",
    "\n",
    "#Classes are modified to 20 species of birds\n",
    "classes = ['background',\n",
    "           'Black_footed_Albatross', 'Laysan_Albatross', 'Sooty_Albatross', 'Groove_Billed_Ani',\n",
    "           'Crested_Auklet', 'Least_Auklet', 'Parakeet_Auklet', 'Rhinoceros_Auklet',\n",
    "           'Brewer_Blackbird', 'Red_winged_Blackbird', 'Rusty_Blackbird', 'Yellow_headed_Blackbird',\n",
    "           'Bobolink', 'Indigo_Bunting', 'Lazuli_Bunting', 'Painted_Bunting',\n",
    "           'Cardinal', 'Spotted_Catbird', 'Gray_Catbird', 'Yellow_breasted_Chat']\n",
    "\n",
    "#CSV files are modified such that a background class is added to it\n",
    "train_dataset.parse_csv(images_dir=bird_dir,\n",
    "                         labels_filename=os.path.join(root_dir,'dataset/bird_data/train_20birds.csv'),\n",
    "                         input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'])\n",
    "\n",
    "val_dataset.parse_csv(images_dir=bird_dir,\n",
    "                      labels_filename=os.path.join(root_dir,'dataset/bird_data/val_20birds.csv'),\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Set the batch size.\n",
    "\n",
    "batch_size = 16 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('fc7_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv6_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv7_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv8_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv9_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Set the remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning rate scheduler \n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.001\n",
    "    elif epoch < 15:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath= os.path.join(root_dir,'with_bird.h5'), \n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename='Birds_tuning_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule,\n",
    "                                                verbose=1)\n",
    "\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             learning_rate_scheduler,\n",
    "             terminate_on_nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "20/20 [==============================] - ETA: 9:28 - loss: 13.48 - ETA: 8:30 - loss: 13.04 - ETA: 6:25 - loss: 23.06 - ETA: 6:14 - loss: 20.43 - ETA: 5:56 - loss: 18.71 - ETA: 5:36 - loss: 18.15 - ETA: 5:14 - loss: 17.80 - ETA: 4:52 - loss: 17.45 - ETA: 4:29 - loss: 17.36 - ETA: 4:05 - loss: 17.13 - ETA: 3:41 - loss: 17.21 - ETA: 3:17 - loss: 17.45 - ETA: 2:53 - loss: 17.31 - ETA: 2:28 - loss: 16.99 - ETA: 2:04 - loss: 16.94 - ETA: 1:39 - loss: 16.84 - ETA: 1:14 - loss: 16.48 - ETA: 49s - loss: 16.2485 - ETA: 25s - loss: 15.957 - 630s 32s/step - loss: 15.6724 - val_loss: 10.5850\n",
      "\n",
      "Epoch 00003: val_loss improved from 12.32413 to 10.58504, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "20/20 [==============================] - ETA: 8:09 - loss: 10.39 - ETA: 7:43 - loss: 9.5650 - ETA: 7:16 - loss: 10.32 - ETA: 6:51 - loss: 10.11 - ETA: 6:25 - loss: 10.20 - ETA: 5:59 - loss: 10.31 - ETA: 5:33 - loss: 10.17 - ETA: 5:07 - loss: 10.10 - ETA: 4:42 - loss: 10.25 - ETA: 4:16 - loss: 10.16 - ETA: 3:50 - loss: 10.16 - ETA: 3:25 - loss: 10.14 - ETA: 2:59 - loss: 10.07 - ETA: 2:33 - loss: 10.03 - ETA: 2:08 - loss: 10.01 - ETA: 1:42 - loss: 10.01 - ETA: 1:16 - loss: 10.16 - ETA: 51s - loss: 10.2599 - ETA: 25s - loss: 10.376 - 642s 32s/step - loss: 10.4757 - val_loss: 9.5244\n",
      "\n",
      "Epoch 00004: val_loss improved from 10.58504 to 9.52443, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "20/20 [==============================] - ETA: 8:06 - loss: 12.05 - ETA: 7:41 - loss: 12.03 - ETA: 7:14 - loss: 11.84 - ETA: 6:49 - loss: 11.61 - ETA: 6:23 - loss: 11.36 - ETA: 5:58 - loss: 11.24 - ETA: 5:33 - loss: 11.23 - ETA: 5:07 - loss: 11.17 - ETA: 4:41 - loss: 10.87 - ETA: 4:02 - loss: 10.67 - ETA: 3:38 - loss: 10.40 - ETA: 3:15 - loss: 10.19 - ETA: 2:51 - loss: 10.03 - ETA: 2:27 - loss: 10.05 - ETA: 2:03 - loss: 9.9766 - ETA: 1:38 - loss: 9.910 - ETA: 1:14 - loss: 9.821 - ETA: 49s - loss: 9.770 - ETA: 24s - loss: 9.80 - 627s 31s/step - loss: 9.7742 - val_loss: 7.9381\n",
      "\n",
      "Epoch 00005: val_loss improved from 9.52443 to 7.93813, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0001.\n",
      "20/20 [==============================] - ETA: 8:05 - loss: 9.551 - ETA: 7:40 - loss: 9.502 - ETA: 7:14 - loss: 9.341 - ETA: 6:49 - loss: 9.102 - ETA: 6:23 - loss: 9.068 - ETA: 5:58 - loss: 8.993 - ETA: 5:32 - loss: 8.989 - ETA: 5:06 - loss: 8.896 - ETA: 4:41 - loss: 8.799 - ETA: 4:15 - loss: 8.834 - ETA: 3:50 - loss: 8.894 - ETA: 3:24 - loss: 8.899 - ETA: 2:59 - loss: 8.893 - ETA: 2:33 - loss: 8.887 - ETA: 2:07 - loss: 8.884 - ETA: 1:42 - loss: 8.885 - ETA: 1:16 - loss: 8.839 - ETA: 51s - loss: 8.826 - ETA: 25s - loss: 8.78 - 641s 32s/step - loss: 8.7966 - val_loss: 7.7555\n",
      "\n",
      "Epoch 00006: val_loss improved from 7.93813 to 7.75550, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0001.\n",
      "20/20 [==============================] - ETA: 8:07 - loss: 8.357 - ETA: 7:41 - loss: 8.522 - ETA: 7:17 - loss: 8.504 - ETA: 6:53 - loss: 8.556 - ETA: 6:27 - loss: 8.828 - ETA: 6:00 - loss: 8.830 - ETA: 5:34 - loss: 8.883 - ETA: 5:08 - loss: 8.828 - ETA: 4:42 - loss: 8.865 - ETA: 4:17 - loss: 8.835 - ETA: 3:51 - loss: 8.842 - ETA: 3:25 - loss: 8.793 - ETA: 2:59 - loss: 8.747 - ETA: 2:34 - loss: 8.740 - ETA: 2:08 - loss: 8.663 - ETA: 1:42 - loss: 8.576 - ETA: 1:14 - loss: 8.550 - ETA: 49s - loss: 8.418 - ETA: 24s - loss: 8.34 - 629s 31s/step - loss: 8.2845 - val_loss: 7.5802\n",
      "\n",
      "Epoch 00007: val_loss improved from 7.75550 to 7.58016, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0001.\n",
      "20/20 [==============================] - ETA: 8:11 - loss: 7.958 - ETA: 7:42 - loss: 8.008 - ETA: 7:17 - loss: 7.980 - ETA: 6:50 - loss: 7.624 - ETA: 6:25 - loss: 7.909 - ETA: 5:59 - loss: 8.064 - ETA: 5:33 - loss: 8.194 - ETA: 5:07 - loss: 8.417 - ETA: 4:42 - loss: 8.513 - ETA: 4:16 - loss: 8.561 - ETA: 3:50 - loss: 8.536 - ETA: 3:25 - loss: 8.472 - ETA: 2:59 - loss: 8.518 - ETA: 2:33 - loss: 8.490 - ETA: 2:08 - loss: 8.432 - ETA: 1:42 - loss: 8.386 - ETA: 1:16 - loss: 8.343 - ETA: 51s - loss: 8.365 - ETA: 25s - loss: 8.37 - 641s 32s/step - loss: 8.3321 - val_loss: 7.5068\n",
      "\n",
      "Epoch 00008: val_loss improved from 7.58016 to 7.50684, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0001.\n",
      "20/20 [==============================] - ETA: 8:10 - loss: 8.023 - ETA: 7:41 - loss: 8.369 - ETA: 7:15 - loss: 8.463 - ETA: 6:50 - loss: 8.218 - ETA: 6:24 - loss: 8.190 - ETA: 5:59 - loss: 8.253 - ETA: 5:33 - loss: 8.373 - ETA: 5:07 - loss: 8.241 - ETA: 4:41 - loss: 8.266 - ETA: 4:16 - loss: 8.277 - ETA: 3:50 - loss: 8.358 - ETA: 3:25 - loss: 8.462 - ETA: 2:59 - loss: 8.512 - ETA: 2:33 - loss: 8.529 - ETA: 2:08 - loss: 8.565 - ETA: 1:42 - loss: 8.568 - ETA: 1:16 - loss: 8.509 - ETA: 51s - loss: 8.486 - ETA: 25s - loss: 8.47 - 641s 32s/step - loss: 8.4410 - val_loss: 7.4625\n",
      "\n",
      "Epoch 00009: val_loss improved from 7.50684 to 7.46248, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0001.\n",
      "20/20 [==============================] - ETA: 8:08 - loss: 8.404 - ETA: 7:41 - loss: 8.769 - ETA: 7:15 - loss: 8.557 - ETA: 5:53 - loss: 8.429 - ETA: 5:41 - loss: 8.088 - ETA: 5:25 - loss: 7.829 - ETA: 5:06 - loss: 7.729 - ETA: 4:46 - loss: 7.702 - ETA: 4:24 - loss: 7.729 - ETA: 4:01 - loss: 7.743 - ETA: 3:38 - loss: 7.741 - ETA: 3:15 - loss: 7.804 - ETA: 2:51 - loss: 7.899 - ETA: 2:27 - loss: 7.918 - ETA: 2:03 - loss: 7.988 - ETA: 1:38 - loss: 8.094 - ETA: 1:14 - loss: 8.136 - ETA: 49s - loss: 8.055 - ETA: 24s - loss: 8.01 - 627s 31s/step - loss: 7.9721 - val_loss: 7.3818\n",
      "\n",
      "Epoch 00010: val_loss improved from 7.46248 to 7.38175, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0001.\n",
      "20/20 [==============================] - ETA: 8:09 - loss: 7.773 - ETA: 7:42 - loss: 7.939 - ETA: 7:15 - loss: 7.896 - ETA: 6:50 - loss: 7.968 - ETA: 6:24 - loss: 7.929 - ETA: 5:58 - loss: 7.991 - ETA: 5:33 - loss: 7.986 - ETA: 5:07 - loss: 8.004 - ETA: 4:42 - loss: 8.078 - ETA: 4:16 - loss: 8.042 - ETA: 3:50 - loss: 7.912 - ETA: 3:25 - loss: 7.872 - ETA: 2:59 - loss: 7.851 - ETA: 2:33 - loss: 7.876 - ETA: 2:08 - loss: 7.886 - ETA: 1:42 - loss: 7.891 - ETA: 1:16 - loss: 7.870 - ETA: 51s - loss: 7.897 - ETA: 25s - loss: 7.94 - 641s 32s/step - loss: 7.9732 - val_loss: 7.2836\n",
      "\n",
      "Epoch 00011: val_loss improved from 7.38175 to 7.28358, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0001.\n",
      "20/20 [==============================] - ETA: 8:05 - loss: 8.801 - ETA: 7:43 - loss: 8.811 - ETA: 7:15 - loss: 8.743 - ETA: 6:50 - loss: 8.499 - ETA: 6:24 - loss: 8.466 - ETA: 5:58 - loss: 8.486 - ETA: 5:33 - loss: 8.432 - ETA: 5:07 - loss: 8.441 - ETA: 4:41 - loss: 8.440 - ETA: 4:16 - loss: 8.291 - ETA: 3:39 - loss: 8.306 - ETA: 3:15 - loss: 8.161 - ETA: 2:51 - loss: 8.014 - ETA: 2:27 - loss: 7.959 - ETA: 2:03 - loss: 7.929 - ETA: 1:38 - loss: 7.902 - ETA: 1:14 - loss: 7.882 - ETA: 49s - loss: 7.908 - ETA: 24s - loss: 7.92 - 628s 31s/step - loss: 7.9473 - val_loss: 7.2482\n",
      "\n",
      "Epoch 00012: val_loss improved from 7.28358 to 7.24824, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 8:02 - loss: 8.761 - ETA: 7:39 - loss: 9.114 - ETA: 7:15 - loss: 8.997 - ETA: 6:49 - loss: 8.801 - ETA: 6:23 - loss: 8.536 - ETA: 5:57 - loss: 8.316 - ETA: 5:32 - loss: 8.176 - ETA: 5:06 - loss: 8.248 - ETA: 4:41 - loss: 8.229 - ETA: 4:15 - loss: 8.178 - ETA: 3:50 - loss: 8.184 - ETA: 3:24 - loss: 8.138 - ETA: 2:59 - loss: 8.106 - ETA: 2:33 - loss: 8.110 - ETA: 2:08 - loss: 8.125 - ETA: 1:42 - loss: 8.127 - ETA: 1:16 - loss: 8.111 - ETA: 51s - loss: 8.088 - ETA: 25s - loss: 8.06 - 642s 32s/step - loss: 8.0608 - val_loss: 7.2075\n",
      "\n",
      "Epoch 00013: val_loss improved from 7.24824 to 7.20753, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001.\n",
      "20/20 [==============================] - ETA: 8:04 - loss: 7.540 - ETA: 7:39 - loss: 7.556 - ETA: 7:14 - loss: 7.811 - ETA: 6:48 - loss: 7.872 - ETA: 6:23 - loss: 8.018 - ETA: 5:58 - loss: 8.148 - ETA: 5:32 - loss: 8.199 - ETA: 5:07 - loss: 8.308 - ETA: 4:41 - loss: 8.296 - ETA: 4:15 - loss: 8.352 - ETA: 3:50 - loss: 8.200 - ETA: 3:24 - loss: 8.194 - ETA: 2:59 - loss: 8.147 - ETA: 2:33 - loss: 8.151 - ETA: 2:07 - loss: 8.135 - ETA: 1:42 - loss: 8.212 - ETA: 1:16 - loss: 8.164 - ETA: 49s - loss: 8.067 - ETA: 24s - loss: 7.97 - 628s 31s/step - loss: 7.9490 - val_loss: 7.1629\n",
      "\n",
      "Epoch 00014: val_loss improved from 7.20753 to 7.16289, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001.\n",
      "20/20 [==============================] - ETA: 8:16 - loss: 7.188 - ETA: 7:49 - loss: 7.246 - ETA: 7:20 - loss: 7.543 - ETA: 6:54 - loss: 7.603 - ETA: 6:28 - loss: 7.630 - ETA: 6:02 - loss: 7.535 - ETA: 5:36 - loss: 7.586 - ETA: 5:10 - loss: 7.642 - ETA: 4:44 - loss: 7.854 - ETA: 4:18 - loss: 7.939 - ETA: 3:52 - loss: 8.000 - ETA: 3:26 - loss: 7.974 - ETA: 3:00 - loss: 7.900 - ETA: 2:34 - loss: 7.882 - ETA: 2:08 - loss: 7.924 - ETA: 1:43 - loss: 7.965 - ETA: 1:17 - loss: 7.940 - ETA: 51s - loss: 7.909 - ETA: 25s - loss: 7.91 - 644s 32s/step - loss: 7.9120 - val_loss: 7.1214\n",
      "\n",
      "Epoch 00015: val_loss improved from 7.16289 to 7.12141, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:06 - loss: 8.029 - ETA: 7:41 - loss: 7.674 - ETA: 7:15 - loss: 7.636 - ETA: 6:50 - loss: 7.669 - ETA: 6:24 - loss: 7.610 - ETA: 5:59 - loss: 7.747 - ETA: 5:33 - loss: 7.809 - ETA: 5:07 - loss: 7.815 - ETA: 4:42 - loss: 7.796 - ETA: 4:16 - loss: 7.834 - ETA: 3:50 - loss: 7.869 - ETA: 3:24 - loss: 7.946 - ETA: 2:59 - loss: 7.978 - ETA: 2:33 - loss: 7.926 - ETA: 2:08 - loss: 7.998 - ETA: 1:42 - loss: 7.989 - ETA: 1:16 - loss: 8.000 - ETA: 51s - loss: 7.966 - ETA: 25s - loss: 7.94 - 641s 32s/step - loss: 7.9345 - val_loss: 7.0984\n",
      "\n",
      "Epoch 00016: val_loss improved from 7.12141 to 7.09835, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:06 - loss: 7.679 - ETA: 7:41 - loss: 7.741 - ETA: 7:14 - loss: 7.755 - ETA: 6:49 - loss: 7.801 - ETA: 5:41 - loss: 7.701 - ETA: 5:25 - loss: 7.489 - ETA: 5:06 - loss: 7.380 - ETA: 4:46 - loss: 7.314 - ETA: 4:24 - loss: 7.319 - ETA: 4:01 - loss: 7.318 - ETA: 3:38 - loss: 7.304 - ETA: 3:15 - loss: 7.344 - ETA: 2:51 - loss: 7.366 - ETA: 2:27 - loss: 7.414 - ETA: 2:03 - loss: 7.453 - ETA: 1:38 - loss: 7.480 - ETA: 1:14 - loss: 7.522 - ETA: 49s - loss: 7.606 - ETA: 24s - loss: 7.59 - 627s 31s/step - loss: 7.5837 - val_loss: 7.0948\n",
      "\n",
      "Epoch 00017: val_loss improved from 7.09835 to 7.09483, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:04 - loss: 7.650 - ETA: 7:40 - loss: 7.780 - ETA: 7:15 - loss: 7.874 - ETA: 6:49 - loss: 7.684 - ETA: 6:24 - loss: 7.498 - ETA: 5:58 - loss: 7.667 - ETA: 5:32 - loss: 7.701 - ETA: 5:06 - loss: 7.752 - ETA: 4:41 - loss: 7.832 - ETA: 4:15 - loss: 7.917 - ETA: 3:50 - loss: 7.948 - ETA: 3:24 - loss: 7.991 - ETA: 2:59 - loss: 8.037 - ETA: 2:33 - loss: 8.073 - ETA: 2:07 - loss: 8.089 - ETA: 1:42 - loss: 8.092 - ETA: 1:16 - loss: 8.082 - ETA: 51s - loss: 8.056 - ETA: 25s - loss: 8.05 - 641s 32s/step - loss: 8.0877 - val_loss: 7.0732\n",
      "\n",
      "Epoch 00018: val_loss improved from 7.09483 to 7.07317, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:03 - loss: 7.337 - ETA: 7:37 - loss: 7.791 - ETA: 7:12 - loss: 7.723 - ETA: 6:47 - loss: 7.691 - ETA: 6:22 - loss: 7.665 - ETA: 5:57 - loss: 7.695 - ETA: 5:31 - loss: 7.555 - ETA: 5:06 - loss: 7.571 - ETA: 4:40 - loss: 7.613 - ETA: 4:15 - loss: 7.612 - ETA: 3:49 - loss: 7.531 - ETA: 3:15 - loss: 7.435 - ETA: 2:51 - loss: 7.385 - ETA: 2:27 - loss: 7.358 - ETA: 2:03 - loss: 7.317 - ETA: 1:38 - loss: 7.318 - ETA: 1:14 - loss: 7.339 - ETA: 49s - loss: 7.308 - ETA: 24s - loss: 7.32 - 627s 31s/step - loss: 7.3144 - val_loss: 7.0699\n",
      "\n",
      "Epoch 00019: val_loss improved from 7.07317 to 7.06990, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:07 - loss: 7.819 - ETA: 7:41 - loss: 7.618 - ETA: 7:17 - loss: 7.752 - ETA: 6:50 - loss: 8.000 - ETA: 6:24 - loss: 8.025 - ETA: 5:58 - loss: 7.966 - ETA: 5:32 - loss: 7.947 - ETA: 5:07 - loss: 7.841 - ETA: 4:41 - loss: 7.988 - ETA: 4:16 - loss: 7.951 - ETA: 3:50 - loss: 7.854 - ETA: 3:25 - loss: 7.879 - ETA: 2:59 - loss: 7.858 - ETA: 2:33 - loss: 7.886 - ETA: 2:08 - loss: 7.893 - ETA: 1:42 - loss: 7.887 - ETA: 1:16 - loss: 7.900 - ETA: 51s - loss: 7.904 - ETA: 25s - loss: 7.83 - 641s 32s/step - loss: 7.7900 - val_loss: 7.0531\n",
      "\n",
      "Epoch 00020: val_loss improved from 7.06990 to 7.05308, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:06 - loss: 7.958 - ETA: 7:39 - loss: 8.209 - ETA: 7:13 - loss: 7.995 - ETA: 6:48 - loss: 7.937 - ETA: 6:22 - loss: 7.884 - ETA: 5:57 - loss: 7.900 - ETA: 5:32 - loss: 8.087 - ETA: 5:06 - loss: 8.099 - ETA: 4:41 - loss: 8.047 - ETA: 4:15 - loss: 7.956 - ETA: 3:50 - loss: 7.925 - ETA: 3:24 - loss: 7.913 - ETA: 2:59 - loss: 7.921 - ETA: 2:33 - loss: 7.940 - ETA: 2:07 - loss: 7.896 - ETA: 1:42 - loss: 7.804 - ETA: 1:16 - loss: 7.842 - ETA: 51s - loss: 7.869 - ETA: 24s - loss: 7.83 - 627s 31s/step - loss: 7.8093 - val_loss: 7.0549\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 7.05308\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:08 - loss: 6.866 - ETA: 7:42 - loss: 6.945 - ETA: 7:15 - loss: 7.064 - ETA: 6:50 - loss: 6.973 - ETA: 6:24 - loss: 7.025 - ETA: 5:59 - loss: 6.889 - ETA: 5:33 - loss: 7.033 - ETA: 5:07 - loss: 7.145 - ETA: 4:42 - loss: 7.191 - ETA: 4:16 - loss: 7.298 - ETA: 3:50 - loss: 7.411 - ETA: 3:24 - loss: 7.501 - ETA: 2:59 - loss: 7.558 - ETA: 2:33 - loss: 7.526 - ETA: 2:08 - loss: 7.496 - ETA: 1:42 - loss: 7.561 - ETA: 1:16 - loss: 7.504 - ETA: 51s - loss: 7.502 - ETA: 25s - loss: 7.51 - 641s 32s/step - loss: 7.4781 - val_loss: 7.0600\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 7.05308\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 8:06 - loss: 8.078 - ETA: 7:39 - loss: 8.045 - ETA: 7:15 - loss: 7.885 - ETA: 6:49 - loss: 8.055 - ETA: 6:23 - loss: 8.056 - ETA: 5:58 - loss: 7.893 - ETA: 5:32 - loss: 7.914 - ETA: 5:07 - loss: 7.977 - ETA: 4:42 - loss: 7.991 - ETA: 4:16 - loss: 7.991 - ETA: 3:50 - loss: 7.921 - ETA: 3:25 - loss: 7.894 - ETA: 2:59 - loss: 8.009 - ETA: 2:33 - loss: 8.026 - ETA: 2:08 - loss: 8.073 - ETA: 1:42 - loss: 8.103 - ETA: 1:16 - loss: 8.099 - ETA: 51s - loss: 8.055 - ETA: 25s - loss: 8.03 - 642s 32s/step - loss: 8.0084 - val_loss: 7.0451\n",
      "\n",
      "Epoch 00023: val_loss improved from 7.05308 to 7.04513, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:04 - loss: 7.875 - ETA: 7:41 - loss: 7.866 - ETA: 7:15 - loss: 8.036 - ETA: 6:49 - loss: 8.077 - ETA: 6:24 - loss: 7.981 - ETA: 5:26 - loss: 7.908 - ETA: 5:07 - loss: 7.784 - ETA: 4:46 - loss: 7.651 - ETA: 4:24 - loss: 7.579 - ETA: 4:02 - loss: 7.588 - ETA: 3:39 - loss: 7.533 - ETA: 3:15 - loss: 7.477 - ETA: 2:51 - loss: 7.441 - ETA: 2:27 - loss: 7.478 - ETA: 2:03 - loss: 7.492 - ETA: 1:38 - loss: 7.461 - ETA: 1:14 - loss: 7.515 - ETA: 49s - loss: 7.543 - ETA: 24s - loss: 7.58 - 627s 31s/step - loss: 7.5601 - val_loss: 7.0605\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 7.04513\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:05 - loss: 7.630 - ETA: 7:40 - loss: 7.303 - ETA: 7:16 - loss: 7.777 - ETA: 6:50 - loss: 7.766 - ETA: 6:24 - loss: 7.644 - ETA: 5:59 - loss: 7.618 - ETA: 5:33 - loss: 7.582 - ETA: 5:07 - loss: 7.656 - ETA: 4:41 - loss: 7.567 - ETA: 4:16 - loss: 7.625 - ETA: 3:50 - loss: 7.695 - ETA: 3:25 - loss: 7.735 - ETA: 2:59 - loss: 7.685 - ETA: 2:33 - loss: 7.670 - ETA: 2:08 - loss: 7.720 - ETA: 1:42 - loss: 7.728 - ETA: 1:16 - loss: 7.725 - ETA: 51s - loss: 7.740 - ETA: 25s - loss: 7.73 - 642s 32s/step - loss: 7.7548 - val_loss: 7.0381\n",
      "\n",
      "Epoch 00025: val_loss improved from 7.04513 to 7.03810, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:09 - loss: 9.226 - ETA: 7:40 - loss: 8.288 - ETA: 7:15 - loss: 8.071 - ETA: 6:50 - loss: 7.974 - ETA: 6:24 - loss: 7.935 - ETA: 5:58 - loss: 7.804 - ETA: 5:33 - loss: 7.705 - ETA: 5:07 - loss: 7.681 - ETA: 4:41 - loss: 7.621 - ETA: 4:16 - loss: 7.627 - ETA: 3:50 - loss: 7.673 - ETA: 3:25 - loss: 7.652 - ETA: 2:51 - loss: 7.686 - ETA: 2:27 - loss: 7.595 - ETA: 2:03 - loss: 7.507 - ETA: 1:39 - loss: 7.456 - ETA: 1:14 - loss: 7.446 - ETA: 49s - loss: 7.405 - ETA: 24s - loss: 7.39 - 628s 31s/step - loss: 7.3857 - val_loss: 7.0424\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 7.03810\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:06 - loss: 6.699 - ETA: 7:40 - loss: 7.395 - ETA: 7:15 - loss: 7.350 - ETA: 6:49 - loss: 7.450 - ETA: 6:23 - loss: 7.738 - ETA: 5:58 - loss: 7.800 - ETA: 5:33 - loss: 7.787 - ETA: 5:07 - loss: 7.816 - ETA: 4:41 - loss: 7.856 - ETA: 4:16 - loss: 7.860 - ETA: 3:50 - loss: 7.815 - ETA: 3:25 - loss: 7.778 - ETA: 2:59 - loss: 7.767 - ETA: 2:33 - loss: 7.775 - ETA: 2:08 - loss: 7.773 - ETA: 1:42 - loss: 7.765 - ETA: 1:16 - loss: 7.812 - ETA: 51s - loss: 7.825 - ETA: 25s - loss: 7.79 - 642s 32s/step - loss: 7.7651 - val_loss: 7.0248\n",
      "\n",
      "Epoch 00027: val_loss improved from 7.03810 to 7.02476, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:05 - loss: 8.096 - ETA: 7:39 - loss: 8.218 - ETA: 7:14 - loss: 8.132 - ETA: 6:49 - loss: 7.923 - ETA: 6:23 - loss: 7.881 - ETA: 5:57 - loss: 8.019 - ETA: 5:32 - loss: 8.065 - ETA: 5:07 - loss: 8.081 - ETA: 4:41 - loss: 8.129 - ETA: 4:16 - loss: 8.139 - ETA: 3:50 - loss: 8.116 - ETA: 3:24 - loss: 8.052 - ETA: 2:59 - loss: 8.076 - ETA: 2:33 - loss: 8.020 - ETA: 2:08 - loss: 8.045 - ETA: 1:42 - loss: 8.049 - ETA: 1:16 - loss: 8.006 - ETA: 51s - loss: 8.018 - ETA: 25s - loss: 8.02 - 628s 31s/step - loss: 8.0151 - val_loss: 7.0327\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 7.02476\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:05 - loss: 6.142 - ETA: 7:41 - loss: 6.420 - ETA: 7:15 - loss: 6.627 - ETA: 6:50 - loss: 6.854 - ETA: 6:25 - loss: 6.864 - ETA: 5:59 - loss: 6.815 - ETA: 5:33 - loss: 6.682 - ETA: 5:08 - loss: 6.696 - ETA: 4:42 - loss: 6.779 - ETA: 4:16 - loss: 6.869 - ETA: 3:50 - loss: 6.996 - ETA: 3:25 - loss: 7.113 - ETA: 2:59 - loss: 7.230 - ETA: 2:33 - loss: 7.254 - ETA: 2:08 - loss: 7.190 - ETA: 1:42 - loss: 7.218 - ETA: 1:16 - loss: 7.279 - ETA: 51s - loss: 7.309 - ETA: 25s - loss: 7.31 - 642s 32s/step - loss: 7.3531 - val_loss: 7.0468\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 7.02476\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 1e-05.\n",
      "20/20 [==============================] - ETA: 8:04 - loss: 7.758 - ETA: 7:39 - loss: 7.899 - ETA: 7:13 - loss: 8.019 - ETA: 6:48 - loss: 8.141 - ETA: 6:23 - loss: 8.233 - ETA: 5:57 - loss: 8.222 - ETA: 5:32 - loss: 8.108 - ETA: 5:06 - loss: 8.096 - ETA: 4:41 - loss: 8.036 - ETA: 4:15 - loss: 7.988 - ETA: 3:50 - loss: 7.966 - ETA: 3:24 - loss: 7.944 - ETA: 2:59 - loss: 7.962 - ETA: 2:33 - loss: 7.991 - ETA: 2:08 - loss: 8.059 - ETA: 1:42 - loss: 8.050 - ETA: 1:16 - loss: 8.058 - ETA: 51s - loss: 8.005 - ETA: 25s - loss: 7.98 - 642s 32s/step - loss: 7.9732 - val_loss: 7.0147\n",
      "\n",
      "Epoch 00030: val_loss improved from 7.02476 to 7.01473, saving model to C:\\Users\\haili Calnielmon\\Desktop\\myKeras_ssd\\with_bird.h5\n"
     ]
    }
   ],
   "source": [
    "#Training time around 2 hours on GeForce GTX 1050\n",
    "#Set `initial_epoch` and `final_epoch` accordingly for resuming.\n",
    "initial_epoch   = 2\n",
    "final_epoch     = 30\n",
    "steps_per_epoch = 20\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size)\n",
    "                              ,initial_epoch=initial_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
