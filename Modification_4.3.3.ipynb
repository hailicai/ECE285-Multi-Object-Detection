{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Modification 4.3.3 \n",
    "Comparison with Stochastic Gradient Descent</h1></center>\n",
    "\n",
    "This notebook recreates the learning conditions mentioned in the paper SSD: Single Shot MultiBox Detector in order to compare and contrast the performances of other optimization algorithms (Adam and RMSprop) with SSD. <br>\n",
    "This code is taken from https://github.com/pierluigiferrari/ssd_keras with a few minor changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [123, 117, 104] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "swap_channels = [2, 1, 0] # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 20 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_pascal = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "scales_coco = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05] # The anchor box scaling factors used in the original SSD300 for the MS COCO datasets\n",
    "scales = scales_pascal\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 100, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 2: Load some weights into the model.\n",
    "\n",
    "# TODO: Set the path to the weights you want to load.\n",
    "weights_path = './VGG_VOC0712_SSD_300x300_iter_120000.h5'\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False) #original model\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=sgd, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image set 'train.txt': 100%|██████████| 5717/5717 [00:23<00:00, 239.85it/s]\n",
      "Loading images into memory: 100%|██████████| 5717/5717 [00:38<00:00, 150.16it/s]\n",
      "Processing image set 'val.txt': 100%|██████████| 5823/5823 [00:21<00:00, 268.42it/s]\n",
      "Loading images into memory: 100%|██████████| 5823/5823 [00:39<00:00, 162.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "\n",
    "# TODO: Set the paths to the datasets here.\n",
    "\n",
    "# The directories that contain the images.\n",
    "\n",
    "VOC_2012_images_dir      = './VOCdevkit/VOC2012/JPEGImages/'\n",
    "VOC_2012_annotations_dir      = './VOCdevkit/VOC2012/Annotations/'\n",
    "VOC_2012_train_image_set_filename    = './VOCdevkit/VOC2012/ImageSets/Main/train.txt'\n",
    "VOC_2012_val_image_set_filename      = './VOCdevkit/VOC2012/ImageSets/Main/val.txt'\n",
    "\n",
    "# The XML parser needs to now what object class names to look for and in which order to map them to integers.\n",
    "classes = ['background',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat',\n",
    "           'chair', 'cow', 'diningtable', 'dog',\n",
    "           'horse', 'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "train_dataset.parse_xml(images_dirs=[VOC_2012_images_dir],\n",
    "                        image_set_filenames=[VOC_2012_train_image_set_filename],\n",
    "                        annotations_dirs=[VOC_2012_annotations_dir],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "val_dataset.parse_xml(images_dirs=[VOC_2012_images_dir],\n",
    "                      image_set_filenames=[VOC_2012_val_image_set_filename],\n",
    "                      annotations_dirs=[VOC_2012_annotations_dir],\n",
    "                      classes=classes,\n",
    "                      include_classes='all',\n",
    "                      exclude_truncated=False,\n",
    "                      exclude_difficult=True,\n",
    "                      ret=False)\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "#train_dataset.create_hdf5_dataset(file_path='dataset_pascal_voc_07+12_trainval.h5',\n",
    "#                                  resize=False,\n",
    "#                                  variable_image_size=True,\n",
    "#                                  verbose=True)\n",
    "\n",
    "#val_dataset.create_hdf5_dataset(file_path='dataset_pascal_voc_07_test.h5',\n",
    "#                                resize=False,\n",
    "#                                variable_image_size=True,\n",
    "#                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t  5717\n",
      "Number of images in the validation dataset:\t  5823\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "\n",
    "batch_size = 8 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('fc7_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv6_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv7_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv8_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv9_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate schedule.\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='./ssd300_pascal_07+12_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "#model_checkpoint.best = \n",
    "\n",
    "csv_logger = CSVLogger(filename='ssd300_pascal_07+12_training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule,\n",
    "                                                verbose=1)\n",
    "\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             learning_rate_scheduler,\n",
    "             terminate_on_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 378s 76s/step - loss: 4.1340 - val_loss: 3.2596\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.25963, saving model to ./ssd300_pascal_07+12_epoch-01_loss-4.1340_val_loss-3.2596.h5\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 323s 65s/step - loss: 4.2641 - val_loss: 3.4717\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.25963\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 326s 65s/step - loss: 4.1120 - val_loss: 3.9136\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.25963\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 342s 68s/step - loss: 4.3154 - val_loss: 3.9384\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.25963\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 337s 67s/step - loss: 4.8978 - val_loss: 4.1321\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.25963\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 326s 65s/step - loss: 5.1987 - val_loss: 4.4143\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.25963\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 335s 67s/step - loss: 5.6360 - val_loss: 4.6378\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.25963\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 331s 66s/step - loss: 6.2034 - val_loss: 5.0641\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.25963\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 337s 67s/step - loss: 6.4634 - val_loss: 4.9027\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.25963\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "5/5 [==============================] - 331s 66s/step - loss: 6.2365 - val_loss: 5.6023\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.25963\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 10\n",
    "steps_per_epoch = 5\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
