{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c1yeung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\c1yeung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.CSRRD7HKRKC3T3YXA7VY7TAZGLSWDKW6.gfortran-win_amd64.dll\n",
      "C:\\Users\\c1yeung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import shutil\n",
    "from misc_utils.tensor_sampling_utils import sample_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights and setting destination\n",
    "weights_source_path = 'VGG_coco_SSD_300x300_iter_400000.h5'\n",
    "weights_destination_path = 'VGG_coco_SSD_300x300_iter_400000_subsampled_bird_classes.h5'\n",
    "shutil.copy(weights_source_path, weights_destination_path)\n",
    "weights_source_file = h5py.File(weights_source_path, 'r')\n",
    "weights_destination_file = h5py.File(weights_destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers that we will be changing\n",
    "classifier_names = ['conv4_3_norm_mbox_conf',\n",
    "                    'fc7_mbox_conf',\n",
    "                    'conv6_2_mbox_conf',\n",
    "                    'conv7_2_mbox_conf',\n",
    "                    'conv8_2_mbox_conf',\n",
    "                    'conv9_2_mbox_conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c1yeung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Subsample the 20 classes of VOC from COCO\n",
    "\n",
    "n_classes_source = 81 # COCO has 80 classes + background class\n",
    "\n",
    "#These are the COCO classes' indices corresponding to the same classes in VOC\n",
    "classes_of_interest = [0,1,15,16,20,17,18,19,5,2,9,6,3,4,7,40,57,61,59,58,63]\n",
    "\n",
    "for name in classifier_names:\n",
    "    kernel = weights_source_file[name][name]['kernel:0'].value\n",
    "    bias = weights_source_file[name][name]['bias:0'].value\n",
    "    height, width, in_channels, out_channels = kernel.shape\n",
    "    if isinstance(classes_of_interest, (list, tuple)):\n",
    "        subsampling_indices = []\n",
    "        for i in range(int(out_channels/n_classes_source)):\n",
    "            indices = np.array(classes_of_interest) + i * n_classes_source\n",
    "            subsampling_indices.append(indices)\n",
    "        subsampling_indices = list(np.concatenate(subsampling_indices))\n",
    "    elif isinstance(classes_of_interest, int):\n",
    "        subsampling_indices = int(classes_of_interest * (out_channels/n_classes_source))\n",
    "    else:\n",
    "        raise ValueError(\"`classes_of_interest` must be either an integer or a list/tuple.\")\n",
    "\n",
    "    new_kernel, new_bias = sample_tensors(weights_list=[kernel, bias],\n",
    "                                          sampling_instructions=[height, width, in_channels, subsampling_indices],\n",
    "                                          axes=[[3]], # The one bias dimension corresponds to the last kernel dimension.\n",
    "                                          init=['gaussian', 'zeros'],\n",
    "                                          mean=0.0,\n",
    "                                          stddev=0.005)\n",
    "    \n",
    "    # Delete the old weights from the destination file.\n",
    "    del weights_destination_file[name][name]['kernel:0']\n",
    "    del weights_destination_file[name][name]['bias:0']\n",
    "    # Create new datasets for the sub-sampled weights.\n",
    "    weights_destination_file[name][name].create_dataset(name='kernel:0', data=new_kernel)\n",
    "    weights_destination_file[name][name].create_dataset(name='bias:0', data=new_bias)\n",
    "\n",
    "# Make sure all data is written to our output file before this sub-routine exits.\n",
    "weights_destination_file.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the new subsampled model is saved and can be used for evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
